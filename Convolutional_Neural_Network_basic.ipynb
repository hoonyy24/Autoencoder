{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEK1Gt-OF1Af",
        "outputId": "79ee877a-7eb8-4cf8-af03-067bdd05c088"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 53.7MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.75MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.6MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.26MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch [1/5], Loss: 0.1299\n",
            "Epoch [2/5], Loss: 0.0437\n",
            "Epoch [3/5], Loss: 0.0281\n",
            "Epoch [4/5], Loss: 0.0221\n",
            "Epoch [5/5], Loss: 0.0160\n",
            "Training complete!\n",
            "Test Accuracy: 99.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-85ab4c34c847>:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"cnn_mnist.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define transformations (normalization and conversion to tensors)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Converts an image into a PyTorch tensor (values between 0 and 1)\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Standardizes pixel values\n",
        "])\n",
        "\n",
        "# Load MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Create DataLoader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "# Define CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)  # First convolution layer\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)  # Second convolution layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Max pooling layer\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Fully connected layer (input: flattened feature maps)\n",
        "        self.fc2 = nn.Linear(128, 10)  # Output layer (10 classes for digits 0-9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # First convolution + ReLU + MaxPool\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Second convolution + ReLU + MaxPool\n",
        "        x = x.view(-1, 64 * 7 * 7)  # Flatten the feature maps\n",
        "        x = F.relu(self.fc1(x))  # Fully connected layer with ReLU\n",
        "        x = self.fc2(x)  # Output layer\n",
        "        return x\n",
        "\n",
        "# Define the device (use GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = CNN().to(device)\n",
        "# CNN() is first called to create an instance of the model.\n",
        "# Then, to(device) is called to move the model's weights to the GPU.\n",
        "# The model is stored in an object after being moved to the GPU.\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0  # Variable to store total loss for the epoch\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)  # Move images and labels to the same device as the model\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update model parameters\n",
        "\n",
        "        running_loss += loss.item()  # Accumulate loss\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")  # Print epoch loss\n",
        "\n",
        "print(\"Training complete!\")  # Training finished\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()  # Set model to evaluation mode\n",
        "correct = 0  # Counter for correctly predicted samples\n",
        "total = 0  # Counter for total samples\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculations for evaluation\n",
        "    for images, labels in test_loader:  # Iterate over test data\n",
        "        images, labels = images.to(device), labels.to(device)  # Move data to the same device as the model\n",
        "        outputs = model(images)  # Get model predictions\n",
        "        _, predicted = torch.max(outputs.detach(), 1)  # Get the class with the highest probability\n",
        "        total += labels.size(0)  # Update total sample count\n",
        "        correct += (predicted == labels).sum().item()  # Update correct predictions count\n",
        "\n",
        "# Inside torch.no_grad(), gradients are not computed, so there's no need to maintain the computation graph.\n",
        "# Using .detach() or .data on outputs prevents additional memory usage.\n",
        "# Prevents unnecessary gradient updates.\n",
        "\n",
        "# Since this runs inside torch.no_grad(), **automatic differentiation (autograd)** is disabled.\n",
        "# However, using .data may cause unexpected side effects.\n",
        "# The safer approach is to use outputs.detach().\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")  # Print test accuracy\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"cnn_mnist.pth\")\n",
        "\n",
        "# Load the model\n",
        "model.load_state_dict(torch.load(\"cnn_mnist.pth\"))\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#What is transforms.Compose\n",
        "#transforms.Compose() is a function that chains multiple transformations together.\n",
        "#It allows us to apply multiple preprocessing steps to an image sequentially.\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n"
      ],
      "metadata": {
        "id": "YGs9nBpDHHOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#What does ToTensor() do?\n",
        "transforms.ToTensor()\n",
        "\n",
        "#Converts a PIL image (or NumPy array) into a PyTorch tensor.\n",
        "#Scales pixel values from [0, 255] → [0, 1] (floating-point numbers)."
      ],
      "metadata": {
        "id": "3xiSRXdzHHQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Before ToTensor()\n",
        "##A grayscale image has pixel values from 0 to 255.\n",
        "[[  0,  128,  255],\n",
        " [ 50,  200,  100],\n",
        " [ 30,  90,  180]]\n"
      ],
      "metadata": {
        "id": "pJfQi7UKHHTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#After ToTensor()\n",
        "##Pixel values are normalized to [0, 1] by dividing by 255\n",
        " [[  0.0,   0.5,  1.0],\n",
        " [ 0.2,  0.78,  0.39],\n",
        " [ 0.12,  0.35,  0.71]]"
      ],
      "metadata": {
        "id": "xj139FAVHHWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#What does Normalize((0.1307,), (0.3081,)) do?\n",
        "\n",
        "#Normalizes the image using mean and standard deviation"
      ],
      "metadata": {
        "id": "0yHz56uGHHZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define predictions and actual labels\n",
        "outputs = torch.tensor([[2.5, 0.3, 0.2], [0.1, 2.2, 1.8]])  # (batch_size=2, num_classes=3)\n",
        "labels = torch.tensor([0, 1])  # Ground truth labels\n",
        "\n",
        "# Define loss function (CrossEntropyLoss)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(outputs, labels)\n",
        "\n",
        "print(loss)         # tensor(1.1234, grad_fn=<NllLossBackward0>)\n",
        "print(loss.item())  # 1.1234  (float value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV7q64H_HHe1",
        "outputId": "d26657f2-7b69-49a8-920d-16894c4e42c8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.3876)\n",
            "0.38763153553009033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#outputs = model(images) → Model Makes Predictions\n",
        "outputs = model(images)\n",
        "\n",
        "#The input images (images) are passed through the model (CNN network) to obtain predicted values (outputs).\n",
        "#outputs is a tensor with shape (batch_size, num_classes).\n",
        "#For example, if the batch size is 4 and there are 3 classes:\n",
        "outputs.shape = (4, 3)\n",
        "#Each row represents the logits (class scores) predicted by the model for each image.\n",
        "\n",
        "#Example output (outputs)\n",
        "tensor([[1.2, 2.5, 0.8],  # Class scores for the first image\n",
        "        [0.9, 1.8, 3.1],  # Class scores for the second image\n",
        "        [2.1, 0.7, 1.5],  # Class scores for the third image\n",
        "        [0.4, 1.3, 2.2]]) # Class scores for the fourth image\n",
        "#Each image has 3 class scores, and the class with the highest score is the predicted label."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM6YIsXXHHhm",
        "outputId": "c9649d12-21ce-486d-92d0-ee02b16db51d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "# `torch.max(outputs.data, 1)` returns the index of the class with the highest score for each sample.\n",
        "# It returns two values:\n",
        "# `_` → The predicted score (not used here)\n",
        "# `predicted` → The predicted class index (the class with the highest score)\n",
        "\n",
        "# Inside `torch.no_grad()`, gradients are not computed, so there is no need to maintain the computation graph.\n",
        "# Using `.detach()` or `.data` on `outputs` prevents additional memory usage.\n",
        "# Prevents unnecessary gradient updates.\n",
        "\n",
        "# Since this runs inside `torch.no_grad()`, **automatic differentiation (autograd)** is disabled.\n",
        "# However, using `.data` may cause unexpected side effects.\n",
        "# The safer approach is to use `outputs.detach()`.\n"
      ],
      "metadata": {
        "id": "WaoM2vq8HHlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = torch.tensor([1, 2, 0, 1])   # Actual labels (ground truth)\n",
        "predicted = torch.tensor([1, 2, 0, 2])  # Model's predicted values\n",
        "\n",
        "print(predicted == labels)  # tensor([True, True, True, False]) - Comparison result\n",
        "print((predicted == labels).sum())  # tensor(3) - Number of correct predictions\n",
        "print((predicted == labels).sum().item())  # 3 (integer value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJOLhrhLF1rg",
        "outputId": "9bd97d36-b827-49b4-bafa-8e4884b6eb4a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ True,  True,  True, False])\n",
            "tensor(3)\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "331LBS8lF1uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IyP6pLkLF1xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L5Z7yg5_F1zC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GIY4a2eyF19m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}